Args: Namespace(attn_pooling_dropout=0.1, batch_size=128, d_model=128, data_format='pt', disable_epc=0, dropout=0.1, dynamic_hypergraph=1, ecr_target_kappa=0.0001, ecr_warmup_epochs=10, exclude_oob=1, feature_dim_audio=1024, feature_dim_text=1024, feature_dim_video=2048, hyper_heads=1, hyper_multi_head_attention=0, hyper_num_audio=20, hyper_num_text=50, hyper_num_video=10, hyper_tau=1.0, hyper_topk=3, hyper_update_freq=5, is_training=1, itr=1, k=3, kappa=0.1, label_map=7, learning_rate=0.0001, loss_lambda=0.1, loss_mode='bce', num_classes=7, num_ordinal_levels=7, num_workers=8, patience=3, pkl_path='./preprocess/mosi_compact_with_vision.pkl', reg_huber_delta=1.0, reg_loss_type='mae', reg_loss_weight=0.05, root_path='./preprocess/processed_data', seq_len_audio=518, seq_len_text=160, seq_len_video=16, setting_suffix='pt_run11', task_mode='classification', train_epochs=10, use_attn_pooling=0, use_coral=0, use_gpu=True, use_head_ln=0, use_modal_gate=0, use_mosi_ecr=0, weight_decay=1e-05)
Use GPU: cuda
[Info] Number of parameters: 695559
>>> Start training: MultimodalClassifier_multimodal_dm128_nc7_0_pt_run11 >>>
[Info] Loading train data...
train 17230
[Info] train data loaded: 17230 samples
[Info] Loading val data...
val 5743
[Info] val data loaded: 5743 samples
[Info] Loading test data...
test 5744
[Info] test data loaded: 5744 samples
[Info] Processing batch 0/134
[Info] Processing batch 10/134
[Info] Processing batch 20/134
[Info] Processing batch 30/134
[Info] Processing batch 40/134
[Info] Processing batch 50/134
[Info] Processing batch 60/134
[Info] Processing batch 70/134
[Info] Processing batch 80/134
[Info] Processing batch 90/134
[Info] Processing batch 100/134
[Info] Processing batch 110/134
[Info] Processing batch 120/134
[Info] Processing batch 130/134
Epoch: 1, Time: 100.67s | Train Loss: 1.6285288 Vali Loss: 1.2293561 Test Loss: 1.2422459
Validation loss decreased (inf --> 1.229356).  Saving model ...
[Info] Processing batch 0/134
[Info] Processing batch 10/134
[Info] Processing batch 20/134
[Info] Processing batch 30/134
[Info] Processing batch 40/134
[Info] Processing batch 50/134
[Info] Processing batch 60/134
[Info] Processing batch 70/134
[Info] Processing batch 80/134
[Info] Processing batch 90/134
[Info] Processing batch 100/134
[Info] Processing batch 110/134
[Info] Processing batch 120/134
[Info] Processing batch 130/134
Epoch: 2, Time: 97.06s | Train Loss: 1.0037335 Vali Loss: 0.9867784 Test Loss: 0.9898217
Validation loss decreased (1.229356 --> 0.986778).  Saving model ...
[Info] Processing batch 0/134
[Info] Processing batch 10/134
[Info] Processing batch 20/134
[Info] Processing batch 30/134
[Info] Processing batch 40/134
[Info] Processing batch 50/134
[Info] Processing batch 60/134
[Info] Processing batch 70/134
[Info] Processing batch 80/134
[Info] Processing batch 90/134
[Info] Processing batch 100/134
[Info] Processing batch 110/134
[Info] Processing batch 120/134
[Info] Processing batch 130/134
Epoch: 3, Time: 97.54s | Train Loss: 0.8756925 Vali Loss: 0.9282155 Test Loss: 0.9372522
Validation loss decreased (0.986778 --> 0.928216).  Saving model ...
[Info] Processing batch 0/134
[Info] Processing batch 10/134
[Info] Processing batch 20/134
[Info] Processing batch 30/134
[Info] Processing batch 40/134
[Info] Processing batch 50/134
[Info] Processing batch 60/134
[Info] Processing batch 70/134
[Info] Processing batch 80/134
[Info] Processing batch 90/134
[Info] Processing batch 100/134
[Info] Processing batch 110/134
[Info] Processing batch 120/134
[Info] Processing batch 130/134
Epoch: 4, Time: 97.57s | Train Loss: 0.8257910 Vali Loss: 0.8986974 Test Loss: 0.9079443
Validation loss decreased (0.928216 --> 0.898697).  Saving model ...
[Info] Processing batch 0/134
[Info] Processing batch 10/134
[Info] Processing batch 20/134
[Info] Processing batch 30/134
[Info] Processing batch 40/134
[Info] Processing batch 50/134
[Info] Processing batch 60/134
[Info] Processing batch 70/134
[Info] Processing batch 80/134
[Info] Processing batch 90/134
[Info] Processing batch 100/134
[Info] Processing batch 110/134
[Info] Processing batch 120/134
[Info] Processing batch 130/134
Epoch: 5, Time: 96.10s | Train Loss: 0.7913873 Vali Loss: 0.8749395 Test Loss: 0.8844386
Validation loss decreased (0.898697 --> 0.874940).  Saving model ...
[Info] Processing batch 0/134
[Info] Processing batch 10/134
[Info] Processing batch 20/134
[Info] Processing batch 30/134
[Info] Processing batch 40/134
[Info] Processing batch 50/134
[Info] Processing batch 60/134
[Info] Processing batch 70/134
[Info] Processing batch 80/134
[Info] Processing batch 90/134
[Info] Processing batch 100/134
[Info] Processing batch 110/134
[Info] Processing batch 120/134
[Info] Processing batch 130/134
Epoch: 6, Time: 97.27s | Train Loss: 0.7708076 Vali Loss: 0.8552828 Test Loss: 0.8759162
Validation loss decreased (0.874940 --> 0.855283).  Saving model ...
[Info] Processing batch 0/134
[Info] Processing batch 10/134
[Info] Processing batch 20/134
[Info] Processing batch 30/134
[Info] Processing batch 40/134
[Info] Processing batch 50/134
[Info] Processing batch 60/134
[Info] Processing batch 70/134
[Info] Processing batch 80/134
[Info] Processing batch 90/134
[Info] Processing batch 100/134
[Info] Processing batch 110/134
[Info] Processing batch 120/134
[Info] Processing batch 130/134
Epoch: 7, Time: 96.02s | Train Loss: 0.7498861 Vali Loss: 0.8369007 Test Loss: 0.8558564
Validation loss decreased (0.855283 --> 0.836901).  Saving model ...
[Info] Processing batch 0/134
[Info] Processing batch 10/134
[Info] Processing batch 20/134
[Info] Processing batch 30/134
[Info] Processing batch 40/134
[Info] Processing batch 50/134
[Info] Processing batch 60/134
[Info] Processing batch 70/134
[Info] Processing batch 80/134
[Info] Processing batch 90/134
[Info] Processing batch 100/134
[Info] Processing batch 110/134
[Info] Processing batch 120/134
[Info] Processing batch 130/134
Epoch: 8, Time: 97.60s | Train Loss: 0.7322451 Vali Loss: 0.8241096 Test Loss: 0.8438646
Validation loss decreased (0.836901 --> 0.824110).  Saving model ...
[Info] Processing batch 0/134
[Info] Processing batch 10/134
[Info] Processing batch 20/134
[Info] Processing batch 30/134
[Info] Processing batch 40/134
[Info] Processing batch 50/134
[Info] Processing batch 60/134
[Info] Processing batch 70/134
[Info] Processing batch 80/134
[Info] Processing batch 90/134
[Info] Processing batch 100/134
[Info] Processing batch 110/134
[Info] Processing batch 120/134
[Info] Processing batch 130/134
Epoch: 9, Time: 97.83s | Train Loss: 0.7166746 Vali Loss: 0.8230706 Test Loss: 0.8368158
Validation loss decreased (0.824110 --> 0.823071).  Saving model ...
[Info] Processing batch 0/134
[Info] Processing batch 10/134
[Info] Processing batch 20/134
[Info] Processing batch 30/134
[Info] Processing batch 40/134
[Info] Processing batch 50/134
[Info] Processing batch 60/134
[Info] Processing batch 70/134
[Info] Processing batch 80/134
[Info] Processing batch 90/134
[Info] Processing batch 100/134
[Info] Processing batch 110/134
[Info] Processing batch 120/134
[Info] Processing batch 130/134
Epoch: 10, Time: 96.33s | Train Loss: 0.7013120 Vali Loss: 0.8060212 Test Loss: 0.8209401
Validation loss decreased (0.823071 --> 0.806021).  Saving model ...
>>> Testing: MultimodalClassifier_multimodal_dm128_nc7_0_pt_run11 <<<
[Info] Loading test data...
test 5744
[Info] test data loaded: 5744 samples
Accuracy: 0.7279
F1 Score (Macro): 0.7186
F1 Score (Weighted): 0.7262

Classification Report:
              precision    recall  f1-score   support

         0.0     0.7519    0.7846    0.7679      1128
         1.0     0.5300    0.5024    0.5158       633
         2.0     0.8214    0.6928    0.7516       498
         3.0     0.7860    0.8322    0.8084       715
         4.0     0.6887    0.6859    0.6873      1216
         5.0     0.7773    0.8393    0.8071      1002
         6.0     0.7304    0.6576    0.6921       552

    accuracy                         0.7279      5744
   macro avg     0.7265    0.7135    0.7186      5744
weighted avg     0.7267    0.7279    0.7262      5744


Confusion Matrix:
[[885 116   3   3  50  49  22]
 [140 318   2  25  94  26  28]
 [ 22   6 345   5  42  50  28]
 [  3  25   4 595  68  11   9]
 [ 48  88  18 101 834  87  40]
 [ 46  11  19   8  70 841   7]
 [ 33  36  29  20  53  18 363]]


