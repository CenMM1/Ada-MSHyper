Args: Namespace(attn_pooling_dropout=0.1, batch_size=128, d_model=128, data_format='pt', disable_epc=0, dropout=0.1, dynamic_hypergraph=1, ecr_target_kappa=0.0001, ecr_warmup_epochs=10, exclude_oob=1, feature_dim_audio=1024, feature_dim_text=1024, feature_dim_video=2048, hyper_heads=1, hyper_multi_head_attention=0, hyper_num_audio=30, hyper_num_text=50, hyper_num_video=15, hyper_tau=0.5, hyper_topk=3, hyper_update_freq=5, is_training=1, itr=1, k=3, kappa=0.1, label_map=7, learning_rate=0.0001, loss_lambda=0.1, loss_mode='bce', num_classes=7, num_ordinal_levels=7, num_workers=8, patience=3, pkl_path='./preprocess/mosi_compact_with_vision.pkl', reg_huber_delta=1.0, reg_loss_type='mae', reg_loss_weight=0.05, root_path='./preprocess/processed_data', seq_len_audio=518, seq_len_text=160, seq_len_video=16, setting_suffix='pt_run2_4', task_mode='classification', train_epochs=10, use_attn_pooling=0, use_coral=0, use_gpu=True, use_head_ln=0, use_modal_gate=0, use_mosi_ecr=0, weight_decay=1e-05)
Use GPU: cuda
[Info] Number of parameters: 697479
>>> Start training: MultimodalClassifier_multimodal_dm128_nc7_0_pt_run2_4 >>>
[Info] Loading train data...
train 17230
[Info] train data loaded: 17230 samples
[Info] Loading val data...
val 5743
[Info] val data loaded: 5743 samples
[Info] Loading test data...
test 5744
[Info] test data loaded: 5744 samples
[Info] Processing batch 0/134
[Info] Processing batch 10/134
[Info] Processing batch 20/134
[Info] Processing batch 30/134
[Info] Processing batch 40/134
[Info] Processing batch 50/134
[Info] Processing batch 60/134
[Info] Processing batch 70/134
[Info] Processing batch 80/134
[Info] Processing batch 90/134
[Info] Processing batch 100/134
[Info] Processing batch 110/134
[Info] Processing batch 120/134
[Info] Processing batch 130/134
Epoch: 1, Time: 97.75s | Train Loss: 1.5634387 Vali Loss: 1.0959342 Test Loss: 1.1120716
Validation loss decreased (inf --> 1.095934).  Saving model ...
[Info] Processing batch 0/134
[Info] Processing batch 10/134
[Info] Processing batch 20/134
[Info] Processing batch 30/134
[Info] Processing batch 40/134
[Info] Processing batch 50/134
[Info] Processing batch 60/134
[Info] Processing batch 70/134
[Info] Processing batch 80/134
[Info] Processing batch 90/134
[Info] Processing batch 100/134
[Info] Processing batch 110/134
[Info] Processing batch 120/134
[Info] Processing batch 130/134
Epoch: 2, Time: 93.15s | Train Loss: 0.9422476 Vali Loss: 0.9146408 Test Loss: 0.9380015
Validation loss decreased (1.095934 --> 0.914641).  Saving model ...
[Info] Processing batch 0/134
[Info] Processing batch 10/134
[Info] Processing batch 20/134
[Info] Processing batch 30/134
[Info] Processing batch 40/134
[Info] Processing batch 50/134
[Info] Processing batch 60/134
[Info] Processing batch 70/134
[Info] Processing batch 80/134
[Info] Processing batch 90/134
[Info] Processing batch 100/134
[Info] Processing batch 110/134
[Info] Processing batch 120/134
[Info] Processing batch 130/134
Epoch: 3, Time: 94.24s | Train Loss: 0.8360546 Vali Loss: 0.8605585 Test Loss: 0.8869287
Validation loss decreased (0.914641 --> 0.860559).  Saving model ...
[Info] Processing batch 0/134
[Info] Processing batch 10/134
[Info] Processing batch 20/134
[Info] Processing batch 30/134
[Info] Processing batch 40/134
[Info] Processing batch 50/134
[Info] Processing batch 60/134
[Info] Processing batch 70/134
[Info] Processing batch 80/134
[Info] Processing batch 90/134
[Info] Processing batch 100/134
[Info] Processing batch 110/134
[Info] Processing batch 120/134
[Info] Processing batch 130/134
Epoch: 4, Time: 99.13s | Train Loss: 0.7885189 Vali Loss: 0.8229816 Test Loss: 0.8475159
Validation loss decreased (0.860559 --> 0.822982).  Saving model ...
[Info] Processing batch 0/134
[Info] Processing batch 10/134
[Info] Processing batch 20/134
[Info] Processing batch 30/134
[Info] Processing batch 40/134
[Info] Processing batch 50/134
[Info] Processing batch 60/134
[Info] Processing batch 70/134
[Info] Processing batch 80/134
[Info] Processing batch 90/134
[Info] Processing batch 100/134
[Info] Processing batch 110/134
[Info] Processing batch 120/134
[Info] Processing batch 130/134
Epoch: 5, Time: 94.43s | Train Loss: 0.7481345 Vali Loss: 0.8033670 Test Loss: 0.8258982
Validation loss decreased (0.822982 --> 0.803367).  Saving model ...
[Info] Processing batch 0/134
[Info] Processing batch 10/134
[Info] Processing batch 20/134
[Info] Processing batch 30/134
[Info] Processing batch 40/134
[Info] Processing batch 50/134
[Info] Processing batch 60/134
[Info] Processing batch 70/134
[Info] Processing batch 80/134
[Info] Processing batch 90/134
[Info] Processing batch 100/134
[Info] Processing batch 110/134
[Info] Processing batch 120/134
[Info] Processing batch 130/134
Epoch: 6, Time: 98.30s | Train Loss: 0.7265019 Vali Loss: 0.8056747 Test Loss: 0.8251754
EarlyStopping counter: 1 out of 3
[Info] Processing batch 0/134
[Info] Processing batch 10/134
[Info] Processing batch 20/134
[Info] Processing batch 30/134
[Info] Processing batch 40/134
[Info] Processing batch 50/134
[Info] Processing batch 60/134
[Info] Processing batch 70/134
[Info] Processing batch 80/134
[Info] Processing batch 90/134
[Info] Processing batch 100/134
[Info] Processing batch 110/134
[Info] Processing batch 120/134
[Info] Processing batch 130/134
Epoch: 7, Time: 96.71s | Train Loss: 0.7097866 Vali Loss: 0.7837676 Test Loss: 0.8067992
Validation loss decreased (0.803367 --> 0.783768).  Saving model ...
[Info] Processing batch 0/134
[Info] Processing batch 10/134
[Info] Processing batch 20/134
[Info] Processing batch 30/134
[Info] Processing batch 40/134
[Info] Processing batch 50/134
[Info] Processing batch 60/134
[Info] Processing batch 70/134
[Info] Processing batch 80/134
[Info] Processing batch 90/134
[Info] Processing batch 100/134
[Info] Processing batch 110/134
[Info] Processing batch 120/134
[Info] Processing batch 130/134
Epoch: 8, Time: 96.89s | Train Loss: 0.6971392 Vali Loss: 0.7783140 Test Loss: 0.8009847
Validation loss decreased (0.783768 --> 0.778314).  Saving model ...
[Info] Processing batch 0/134
[Info] Processing batch 10/134
[Info] Processing batch 20/134
[Info] Processing batch 30/134
[Info] Processing batch 40/134
[Info] Processing batch 50/134
[Info] Processing batch 60/134
[Info] Processing batch 70/134
[Info] Processing batch 80/134
[Info] Processing batch 90/134
[Info] Processing batch 100/134
[Info] Processing batch 110/134
[Info] Processing batch 120/134
[Info] Processing batch 130/134
Epoch: 9, Time: 97.33s | Train Loss: 0.6831648 Vali Loss: 0.7774938 Test Loss: 0.7974155
Validation loss decreased (0.778314 --> 0.777494).  Saving model ...
[Info] Processing batch 0/134
[Info] Processing batch 10/134
[Info] Processing batch 20/134
[Info] Processing batch 30/134
[Info] Processing batch 40/134
[Info] Processing batch 50/134
[Info] Processing batch 60/134
[Info] Processing batch 70/134
[Info] Processing batch 80/134
[Info] Processing batch 90/134
[Info] Processing batch 100/134
[Info] Processing batch 110/134
[Info] Processing batch 120/134
[Info] Processing batch 130/134
Epoch: 10, Time: 97.16s | Train Loss: 0.6728883 Vali Loss: 0.7713466 Test Loss: 0.7921517
Validation loss decreased (0.777494 --> 0.771347).  Saving model ...
>>> Testing: MultimodalClassifier_multimodal_dm128_nc7_0_pt_run2_4 <<<
[Info] Loading test data...
test 5744
[Info] test data loaded: 5744 samples
Accuracy: 0.7282
F1 Score (Macro): 0.7177
F1 Score (Weighted): 0.7267

Classification Report:
              precision    recall  f1-score   support

         0.0     0.7565    0.7766    0.7664      1128
         1.0     0.5217    0.4945    0.5077       633
         2.0     0.7697    0.7048    0.7358       498
         3.0     0.8044    0.8224    0.8133       715
         4.0     0.6967    0.6875    0.6921      1216
         5.0     0.7843    0.8453    0.8136      1002
         6.0     0.7168    0.6739    0.6947       552

    accuracy                         0.7282      5744
   macro avg     0.7214    0.7150    0.7177      5744
weighted avg     0.7261    0.7282    0.7267      5744


Confusion Matrix:
[[876 120   8   3  40  52  29]
 [144 313   2  25  95  26  28]
 [ 20   5 351   3  40  47  32]
 [  5  26   4 588  72  12   8]
 [ 48  93  27  88 836  82  42]
 [ 39  10  27   5  66 847   8]
 [ 26  33  37  19  51  14 372]]


