Args: Namespace(attn_pooling_dropout=0.1, batch_size=128, d_model=128, data_format='pt', disable_epc=0, dropout=0.1, dynamic_hypergraph=1, ecr_target_kappa=0.0001, ecr_warmup_epochs=10, exclude_oob=1, feature_dim_audio=1024, feature_dim_text=1024, feature_dim_video=2048, hyper_heads=1, hyper_multi_head_attention=0, hyper_num_audio=20, hyper_num_text=50, hyper_num_video=10, hyper_tau=0.5, hyper_topk=3, hyper_update_freq=5, is_training=1, itr=1, k=6, kappa=0.1, label_map=7, learning_rate=0.0001, loss_lambda=0.1, loss_mode='bce', num_classes=7, num_ordinal_levels=7, num_workers=8, patience=3, pkl_path='./preprocess/mosi_compact_with_vision.pkl', reg_huber_delta=1.0, reg_loss_type='mae', reg_loss_weight=0.05, root_path='./preprocess/processed_data', seq_len_audio=518, seq_len_text=160, seq_len_video=16, setting_suffix='pt_run4', task_mode='classification', train_epochs=10, use_attn_pooling=0, use_coral=0, use_gpu=True, use_head_ln=0, use_modal_gate=0, use_mosi_ecr=0, weight_decay=1e-05)
Use GPU: cuda
[Info] Number of parameters: 695559
>>> Start training: MultimodalClassifier_multimodal_dm128_nc7_0_pt_run4 >>>
[Info] Loading train data...
train 17230
[Info] train data loaded: 17230 samples
[Info] Loading val data...
val 5743
[Info] val data loaded: 5743 samples
[Info] Loading test data...
test 5744
[Info] test data loaded: 5744 samples
[Info] Processing batch 0/134
[Info] Processing batch 10/134
[Info] Processing batch 20/134
[Info] Processing batch 30/134
[Info] Processing batch 40/134
[Info] Processing batch 50/134
[Info] Processing batch 60/134
[Info] Processing batch 70/134
[Info] Processing batch 80/134
[Info] Processing batch 90/134
[Info] Processing batch 100/134
[Info] Processing batch 110/134
[Info] Processing batch 120/134
[Info] Processing batch 130/134
Epoch: 1, Time: 97.41s | Train Loss: 1.5643487 Vali Loss: 1.0738834 Test Loss: 1.0927814
Validation loss decreased (inf --> 1.073883).  Saving model ...
[Info] Processing batch 0/134
[Info] Processing batch 10/134
[Info] Processing batch 20/134
[Info] Processing batch 30/134
[Info] Processing batch 40/134
[Info] Processing batch 50/134
[Info] Processing batch 60/134
[Info] Processing batch 70/134
[Info] Processing batch 80/134
[Info] Processing batch 90/134
[Info] Processing batch 100/134
[Info] Processing batch 110/134
[Info] Processing batch 120/134
[Info] Processing batch 130/134
Epoch: 2, Time: 93.56s | Train Loss: 0.9206955 Vali Loss: 0.9053112 Test Loss: 0.9261083
Validation loss decreased (1.073883 --> 0.905311).  Saving model ...
[Info] Processing batch 0/134
[Info] Processing batch 10/134
[Info] Processing batch 20/134
[Info] Processing batch 30/134
[Info] Processing batch 40/134
[Info] Processing batch 50/134
[Info] Processing batch 60/134
[Info] Processing batch 70/134
[Info] Processing batch 80/134
[Info] Processing batch 90/134
[Info] Processing batch 100/134
[Info] Processing batch 110/134
[Info] Processing batch 120/134
[Info] Processing batch 130/134
Epoch: 3, Time: 94.41s | Train Loss: 0.8241836 Vali Loss: 0.8467786 Test Loss: 0.8679305
Validation loss decreased (0.905311 --> 0.846779).  Saving model ...
[Info] Processing batch 0/134
[Info] Processing batch 10/134
[Info] Processing batch 20/134
[Info] Processing batch 30/134
[Info] Processing batch 40/134
[Info] Processing batch 50/134
[Info] Processing batch 60/134
[Info] Processing batch 70/134
[Info] Processing batch 80/134
[Info] Processing batch 90/134
[Info] Processing batch 100/134
[Info] Processing batch 110/134
[Info] Processing batch 120/134
[Info] Processing batch 130/134
Epoch: 4, Time: 94.31s | Train Loss: 0.7713485 Vali Loss: 0.8200118 Test Loss: 0.8346594
Validation loss decreased (0.846779 --> 0.820012).  Saving model ...
[Info] Processing batch 0/134
[Info] Processing batch 10/134
[Info] Processing batch 20/134
[Info] Processing batch 30/134
[Info] Processing batch 40/134
[Info] Processing batch 50/134
[Info] Processing batch 60/134
[Info] Processing batch 70/134
[Info] Processing batch 80/134
[Info] Processing batch 90/134
[Info] Processing batch 100/134
[Info] Processing batch 110/134
[Info] Processing batch 120/134
[Info] Processing batch 130/134
Epoch: 5, Time: 95.93s | Train Loss: 0.7393817 Vali Loss: 0.8030584 Test Loss: 0.8233748
Validation loss decreased (0.820012 --> 0.803058).  Saving model ...
[Info] Processing batch 0/134
[Info] Processing batch 10/134
[Info] Processing batch 20/134
[Info] Processing batch 30/134
[Info] Processing batch 40/134
[Info] Processing batch 50/134
[Info] Processing batch 60/134
[Info] Processing batch 70/134
[Info] Processing batch 80/134
[Info] Processing batch 90/134
[Info] Processing batch 100/134
[Info] Processing batch 110/134
[Info] Processing batch 120/134
[Info] Processing batch 130/134
Epoch: 6, Time: 95.33s | Train Loss: 0.7184896 Vali Loss: 0.7875961 Test Loss: 0.8043104
Validation loss decreased (0.803058 --> 0.787596).  Saving model ...
[Info] Processing batch 0/134
[Info] Processing batch 10/134
[Info] Processing batch 20/134
[Info] Processing batch 30/134
[Info] Processing batch 40/134
[Info] Processing batch 50/134
[Info] Processing batch 60/134
[Info] Processing batch 70/134
[Info] Processing batch 80/134
[Info] Processing batch 90/134
[Info] Processing batch 100/134
[Info] Processing batch 110/134
[Info] Processing batch 120/134
[Info] Processing batch 130/134
Epoch: 7, Time: 94.87s | Train Loss: 0.7036691 Vali Loss: 0.7786049 Test Loss: 0.7972589
Validation loss decreased (0.787596 --> 0.778605).  Saving model ...
[Info] Processing batch 0/134
[Info] Processing batch 10/134
[Info] Processing batch 20/134
[Info] Processing batch 30/134
[Info] Processing batch 40/134
[Info] Processing batch 50/134
[Info] Processing batch 60/134
[Info] Processing batch 70/134
[Info] Processing batch 80/134
[Info] Processing batch 90/134
[Info] Processing batch 100/134
[Info] Processing batch 110/134
[Info] Processing batch 120/134
[Info] Processing batch 130/134
Epoch: 8, Time: 93.78s | Train Loss: 0.6893847 Vali Loss: 0.7715532 Test Loss: 0.7913603
Validation loss decreased (0.778605 --> 0.771553).  Saving model ...
[Info] Processing batch 0/134
[Info] Processing batch 10/134
[Info] Processing batch 20/134
[Info] Processing batch 30/134
[Info] Processing batch 40/134
[Info] Processing batch 50/134
[Info] Processing batch 60/134
[Info] Processing batch 70/134
[Info] Processing batch 80/134
[Info] Processing batch 90/134
[Info] Processing batch 100/134
[Info] Processing batch 110/134
[Info] Processing batch 120/134
[Info] Processing batch 130/134
Epoch: 9, Time: 93.80s | Train Loss: 0.6779241 Vali Loss: 0.7662047 Test Loss: 0.7856253
Validation loss decreased (0.771553 --> 0.766205).  Saving model ...
[Info] Processing batch 0/134
[Info] Processing batch 10/134
[Info] Processing batch 20/134
[Info] Processing batch 30/134
[Info] Processing batch 40/134
[Info] Processing batch 50/134
[Info] Processing batch 60/134
[Info] Processing batch 70/134
[Info] Processing batch 80/134
[Info] Processing batch 90/134
[Info] Processing batch 100/134
[Info] Processing batch 110/134
[Info] Processing batch 120/134
[Info] Processing batch 130/134
Epoch: 10, Time: 95.70s | Train Loss: 0.6663518 Vali Loss: 0.7587422 Test Loss: 0.7800780
Validation loss decreased (0.766205 --> 0.758742).  Saving model ...
>>> Testing: MultimodalClassifier_multimodal_dm128_nc7_0_pt_run4 <<<
[Info] Loading test data...
test 5744
[Info] test data loaded: 5744 samples
Accuracy: 0.7291
F1 Score (Macro): 0.7156
F1 Score (Weighted): 0.7250

Classification Report:
              precision    recall  f1-score   support

         0.0     0.7332    0.8112    0.7702      1128
         1.0     0.5607    0.4234    0.4824       633
         2.0     0.8206    0.6888    0.7489       498
         3.0     0.7927    0.8182    0.8052       715
         4.0     0.6832    0.7023    0.6926      1216
         5.0     0.7895    0.8383    0.8132      1002
         6.0     0.6989    0.6938    0.6964       552

    accuracy                         0.7291      5744
   macro avg     0.7255    0.7109    0.7156      5744
weighted avg     0.7251    0.7291    0.7250      5744


Confusion Matrix:
[[915  85   5   3  43  47  30]
 [174 268   2  28 108  23  30]
 [ 21   4 343   5  42  43  40]
 [  3  24   3 585  80  12   8]
 [ 57  66  19  91 854  83  46]
 [ 49   8  23   5  66 840  11]
 [ 29  23  23  21  57  16 383]]


