Args: Namespace(attn_pooling_dropout=0.1, batch_size=128, d_model=128, data_format='pt', disable_epc=0, dropout=0.1, dynamic_hypergraph=1, ecr_target_kappa=0.0001, ecr_warmup_epochs=10, exclude_oob=1, feature_dim_audio=1024, feature_dim_text=1024, feature_dim_video=2048, hyper_heads=1, hyper_multi_head_attention=0, hyper_num_audio=20, hyper_num_text=50, hyper_num_video=10, hyper_tau=0.7, hyper_topk=3, hyper_update_freq=5, is_training=1, itr=1, k=3, kappa=0.1, label_map=7, learning_rate=0.0001, loss_lambda=0.1, loss_mode='bce', num_classes=7, num_ordinal_levels=7, num_workers=8, patience=3, pkl_path='./preprocess/mosi_compact_with_vision.pkl', reg_huber_delta=1.0, reg_loss_type='mae', reg_loss_weight=0.05, root_path='./preprocess/processed_data', seq_len_audio=518, seq_len_text=160, seq_len_video=16, setting_suffix='pt_run10', task_mode='classification', train_epochs=10, use_attn_pooling=0, use_coral=0, use_gpu=True, use_head_ln=0, use_modal_gate=0, use_mosi_ecr=0, weight_decay=1e-05)
Use GPU: cuda
[Info] Number of parameters: 695559
>>> Start training: MultimodalClassifier_multimodal_dm128_nc7_0_pt_run10 >>>
[Info] Loading train data...
train 17230
[Info] train data loaded: 17230 samples
[Info] Loading val data...
val 5743
[Info] val data loaded: 5743 samples
[Info] Loading test data...
test 5744
[Info] test data loaded: 5744 samples
[Info] Processing batch 0/134
[Info] Processing batch 10/134
[Info] Processing batch 20/134
[Info] Processing batch 30/134
[Info] Processing batch 40/134
[Info] Processing batch 50/134
[Info] Processing batch 60/134
[Info] Processing batch 70/134
[Info] Processing batch 80/134
[Info] Processing batch 90/134
[Info] Processing batch 100/134
[Info] Processing batch 110/134
[Info] Processing batch 120/134
[Info] Processing batch 130/134
Epoch: 1, Time: 99.93s | Train Loss: 1.5858214 Vali Loss: 1.1378341 Test Loss: 1.1613623
Validation loss decreased (inf --> 1.137834).  Saving model ...
[Info] Processing batch 0/134
[Info] Processing batch 10/134
[Info] Processing batch 20/134
[Info] Processing batch 30/134
[Info] Processing batch 40/134
[Info] Processing batch 50/134
[Info] Processing batch 60/134
[Info] Processing batch 70/134
[Info] Processing batch 80/134
[Info] Processing batch 90/134
[Info] Processing batch 100/134
[Info] Processing batch 110/134
[Info] Processing batch 120/134
[Info] Processing batch 130/134
Epoch: 2, Time: 96.58s | Train Loss: 0.9680426 Vali Loss: 0.9483777 Test Loss: 0.9705194
Validation loss decreased (1.137834 --> 0.948378).  Saving model ...
[Info] Processing batch 0/134
[Info] Processing batch 10/134
[Info] Processing batch 20/134
[Info] Processing batch 30/134
[Info] Processing batch 40/134
[Info] Processing batch 50/134
[Info] Processing batch 60/134
[Info] Processing batch 70/134
[Info] Processing batch 80/134
[Info] Processing batch 90/134
[Info] Processing batch 100/134
[Info] Processing batch 110/134
[Info] Processing batch 120/134
[Info] Processing batch 130/134
Epoch: 3, Time: 97.58s | Train Loss: 0.8469325 Vali Loss: 0.8604029 Test Loss: 0.8859884
Validation loss decreased (0.948378 --> 0.860403).  Saving model ...
[Info] Processing batch 0/134
[Info] Processing batch 10/134
[Info] Processing batch 20/134
[Info] Processing batch 30/134
[Info] Processing batch 40/134
[Info] Processing batch 50/134
[Info] Processing batch 60/134
[Info] Processing batch 70/134
[Info] Processing batch 80/134
[Info] Processing batch 90/134
[Info] Processing batch 100/134
[Info] Processing batch 110/134
[Info] Processing batch 120/134
[Info] Processing batch 130/134
Epoch: 4, Time: 97.69s | Train Loss: 0.7802192 Vali Loss: 0.8217763 Test Loss: 0.8452005
Validation loss decreased (0.860403 --> 0.821776).  Saving model ...
[Info] Processing batch 0/134
[Info] Processing batch 10/134
[Info] Processing batch 20/134
[Info] Processing batch 30/134
[Info] Processing batch 40/134
[Info] Processing batch 50/134
[Info] Processing batch 60/134
[Info] Processing batch 70/134
[Info] Processing batch 80/134
[Info] Processing batch 90/134
[Info] Processing batch 100/134
[Info] Processing batch 110/134
[Info] Processing batch 120/134
[Info] Processing batch 130/134
Epoch: 5, Time: 98.09s | Train Loss: 0.7446017 Vali Loss: 0.7984798 Test Loss: 0.8209118
Validation loss decreased (0.821776 --> 0.798480).  Saving model ...
[Info] Processing batch 0/134
[Info] Processing batch 10/134
[Info] Processing batch 20/134
[Info] Processing batch 30/134
[Info] Processing batch 40/134
[Info] Processing batch 50/134
[Info] Processing batch 60/134
[Info] Processing batch 70/134
[Info] Processing batch 80/134
[Info] Processing batch 90/134
[Info] Processing batch 100/134
[Info] Processing batch 110/134
[Info] Processing batch 120/134
[Info] Processing batch 130/134
Epoch: 6, Time: 96.02s | Train Loss: 0.7207672 Vali Loss: 0.7846724 Test Loss: 0.8076111
Validation loss decreased (0.798480 --> 0.784672).  Saving model ...
[Info] Processing batch 0/134
[Info] Processing batch 10/134
[Info] Processing batch 20/134
[Info] Processing batch 30/134
[Info] Processing batch 40/134
[Info] Processing batch 50/134
[Info] Processing batch 60/134
[Info] Processing batch 70/134
[Info] Processing batch 80/134
[Info] Processing batch 90/134
[Info] Processing batch 100/134
[Info] Processing batch 110/134
[Info] Processing batch 120/134
[Info] Processing batch 130/134
Epoch: 7, Time: 97.00s | Train Loss: 0.7065992 Vali Loss: 0.7755840 Test Loss: 0.8004568
Validation loss decreased (0.784672 --> 0.775584).  Saving model ...
[Info] Processing batch 0/134
[Info] Processing batch 10/134
[Info] Processing batch 20/134
[Info] Processing batch 30/134
[Info] Processing batch 40/134
[Info] Processing batch 50/134
[Info] Processing batch 60/134
[Info] Processing batch 70/134
[Info] Processing batch 80/134
[Info] Processing batch 90/134
[Info] Processing batch 100/134
[Info] Processing batch 110/134
[Info] Processing batch 120/134
[Info] Processing batch 130/134
Epoch: 8, Time: 97.40s | Train Loss: 0.6921626 Vali Loss: 0.7694370 Test Loss: 0.7913347
Validation loss decreased (0.775584 --> 0.769437).  Saving model ...
[Info] Processing batch 0/134
[Info] Processing batch 10/134
[Info] Processing batch 20/134
[Info] Processing batch 30/134
[Info] Processing batch 40/134
[Info] Processing batch 50/134
[Info] Processing batch 60/134
[Info] Processing batch 70/134
[Info] Processing batch 80/134
[Info] Processing batch 90/134
[Info] Processing batch 100/134
[Info] Processing batch 110/134
[Info] Processing batch 120/134
[Info] Processing batch 130/134
Epoch: 9, Time: 97.90s | Train Loss: 0.6782996 Vali Loss: 0.7679737 Test Loss: 0.7909827
Validation loss decreased (0.769437 --> 0.767974).  Saving model ...
[Info] Processing batch 0/134
[Info] Processing batch 10/134
[Info] Processing batch 20/134
[Info] Processing batch 30/134
[Info] Processing batch 40/134
[Info] Processing batch 50/134
[Info] Processing batch 60/134
[Info] Processing batch 70/134
[Info] Processing batch 80/134
[Info] Processing batch 90/134
[Info] Processing batch 100/134
[Info] Processing batch 110/134
[Info] Processing batch 120/134
[Info] Processing batch 130/134
Epoch: 10, Time: 97.50s | Train Loss: 0.6719172 Vali Loss: 0.7553861 Test Loss: 0.7821809
Validation loss decreased (0.767974 --> 0.755386).  Saving model ...
>>> Testing: MultimodalClassifier_multimodal_dm128_nc7_0_pt_run10 <<<
[Info] Loading test data...
test 5744
[Info] test data loaded: 5744 samples
Accuracy: 0.7256
F1 Score (Macro): 0.7152
F1 Score (Weighted): 0.7241

Classification Report:
              precision    recall  f1-score   support

         0.0     0.7553    0.7855    0.7701      1128
         1.0     0.5373    0.4897    0.5124       633
         2.0     0.8195    0.6747    0.7401       498
         3.0     0.7818    0.8168    0.7989       715
         4.0     0.7001    0.6719    0.6857      1216
         5.0     0.7956    0.8273    0.8112      1002
         6.0     0.6465    0.7355    0.6881       552

    accuracy                         0.7256      5744
   macro avg     0.7194    0.7145    0.7152      5744
weighted avg     0.7250    0.7256    0.7241      5744


Confusion Matrix:
[[886 112   4   5  41  44  36]
 [138 310   2  27  92  21  43]
 [ 22   6 336   5  33  45  51]
 [  5  24   4 584  72  14  12]
 [ 53  90  19 100 817  72  65]
 [ 46  12  22   8  70 829  15]
 [ 23  23  23  18  42  17 406]]


